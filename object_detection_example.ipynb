{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix conda slow loading https://github.com/pytorch/pytorch/issues/537    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('tensorboard --logdir /tmp/log --host 0.0.0.0 --port 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat url.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import image_manipulations as i_manips\n",
    "from processing_utils import runtime_logic\n",
    "from processing_utils import analysis_utils\n",
    "from processing_utils import load_data\n",
    "from model.retinanet import model as retina_model\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, ColorJitter, FiveCrop, CenterCrop, Lambda, RandomCrop, Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    }
   ],
   "source": [
    "print(f'Cuda available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.cuda.manual_seed(seed)    \n",
    "\n",
    "run_name = \"object_detection_test\"\n",
    "data_root = os.path.join(os.getcwd(), \"dummy_data\")\n",
    "img_directory = os.path.join(data_root, \"train/\")\n",
    "\n",
    "normalize_params_file = f'outputs/norm_params/{run_name}_norm_params.yaml'\n",
    "previous_model_state = None # Pickled model state dictionary path\n",
    "\n",
    "# Can be set to none if TensorboardX isn't installed\n",
    "tensorboard_outpath = None # f'outputs/tensorboard/{run_name}_log' # Set to none for temp\n",
    "\n",
    "n_epochs = 25\n",
    "input_size = 224\n",
    "init_l_rate = 1e-4\n",
    "lr_decay = 0.1\n",
    "lr_decay_epoch = [5, 10, 15]\n",
    "w_decay = 1e-4\n",
    "\n",
    "batch_size = 3\n",
    "num_channels = 3\n",
    "num_classes = 2\n",
    "\n",
    "class_weights = torch.Tensor([1, 1])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "if torch.cuda.is_available():\n",
    "    criterion.cuda()\n",
    "\n",
    "report_results_per_n_batches = {'train':5, 'val':1}\n",
    "save_interval = 9999\n",
    "\n",
    "shutdown_after = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retina_model.resnet18(2, pretrained=False)\n",
    "\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "# model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(previous_model_state)\n",
    "# model.load_state_dict(state_dict)\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get normalize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get normalize parameters\n",
    "all_imgs = i_manips.get_images(img_directory)\n",
    "\n",
    "if os.path.isfile(normalize_params_file):\n",
    "    stream = open(normalize_params_file, 'r')\n",
    "    norm_params = yaml.load(stream)\n",
    "else:\n",
    "    norm_params = i_manips.get_normalize_params(all_imgs, num_bands=num_channels)\n",
    "    analysis_utils.write_normalize_values(norm_params, normalize_params_file)\n",
    "\n",
    "means = norm_params[\"means\"]\n",
    "sdevs = norm_params[\"sdevs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    ColorJitter(0.05, 0.05, 0.05),\n",
    "    ToTensor(),\n",
    "    Normalize([means[0],means[1],means[2]],\n",
    "              [sdevs[0],sdevs[1],sdevs[2]])\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([means[0],means[1],means[2]],\n",
    "              [sdevs[0],sdevs[1],sdevs[2]])\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training data\n",
    "train_data = datasets.ImageFolder(os.path.join(data_root, 'train'),\n",
    "                                  transform=train_transforms)\n",
    "val_data = datasets.ImageFolder(os.path.join(data_root, 'val'),\n",
    "                                transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "val_loader = DataLoader(val_data,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)\n",
    "\n",
    "classes = deepcopy(train_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=init_l_rate, weight_decay=w_decay)\n",
    "train_analysis = runtime_logic.AnnotatedImageAnalysis(model,\n",
    "                                                      classes,\n",
    "                                                      means,\n",
    "                                                      sdevs,\n",
    "                                                      train_loader=train_loader,\n",
    "                                                      val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_analysis.instantiate_loss_tracker('outputs')\n",
    "train_analysis.loss_tracker.setup_output_storage(run_name)\n",
    "train_analysis.instantiate_visualiser(tensorboard_outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {# model components\n",
    "             'run_name':run_name,\n",
    "             'optimizer':optimizer,\n",
    "             'criterion':criterion,\n",
    "\n",
    "             # Hyperparameters\n",
    "             'n_epochs':n_epochs,\n",
    "             'batch_size':batch_size,\n",
    "             'lr_decay':lr_decay,\n",
    "             'lr_decay_epoch':lr_decay_epoch,\n",
    "             # 'lr_decay_patience':lr_decay_patience,\n",
    "             # 'class_weights':class_weights,\n",
    "\n",
    "             # Saving & Information retrieval\n",
    "             'report_interval':report_results_per_n_batches,\n",
    "             'save_interval':save_interval,\n",
    "    \n",
    "             'shutdown':shutdown_after,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [32 out of 82] : 0.8906\n"
     ]
    }
   ],
   "source": [
    "train_analysis.train(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_analysis.loss_tracker.save_model(model, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
