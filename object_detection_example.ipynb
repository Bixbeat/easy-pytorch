{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix conda slow loading https://github.com/pytorch/pytorch/issues/537    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('tensorboard --logdir /tmp/log --host 0.0.0.0 --port 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat url.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import image_manipulations as i_manips\n",
    "from processing_utils import runtime_logic\n",
    "from processing_utils import analysis_utils\n",
    "from processing_utils import load_data\n",
    "from model.retinanet import model as retina_model\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, ColorJitter, FiveCrop, CenterCrop, Lambda, RandomCrop, Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'Cuda available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.cuda.manual_seed(seed)    \n",
    "\n",
    "run_name = \"object_detection_test\"\n",
    "data_root = os.path.join(os.getcwd(), \"dummy_data/00007\")\n",
    "train_dir = os.path.join(data_root, \"train/\")\n",
    "val_dir = os.path.join(data_root, \"val/\")\n",
    "\n",
    "train_file = os.path.join(train_dir, \"annotations.csv\")\n",
    "val_file = os.path.join(val_dir, \"annotations.csv\")\n",
    "class_file = os.path.join(data_root, \"classmap.csv\")\n",
    "\n",
    "normalize_params_file = f'outputs/norm_params/{run_name}_norm_params.yaml'\n",
    "previous_model_state = None # Pickled model state dictionary path\n",
    "\n",
    "# Can be set to none if TensorboardX isn't installed\n",
    "tensorboard_outpath = None # f'outputs/tensorboard/{run_name}_log' # Set to none for temp\n",
    "\n",
    "n_epochs = 25\n",
    "input_size = 224\n",
    "init_l_rate = 1e-4\n",
    "lr_decay = 0.1\n",
    "lr_decay_epoch = [5, 10, 15]\n",
    "w_decay = 1e-4\n",
    "\n",
    "batch_size = 2\n",
    "num_channels = 1\n",
    "\n",
    "# class_weights = torch.Tensor([1, 1])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    criterion.cuda()\n",
    "\n",
    "report_results_per_n_batches = {'train':5, 'val':1}\n",
    "save_interval = 9999\n",
    "\n",
    "shutdown_after = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retina_model.resnet18(2, pretrained=False)\n",
    "\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "# model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(previous_model_state)\n",
    "# model.load_state_dict(state_dict)\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get normalize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anteagroup/anaconda3/envs/easy_pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# # Get normalize parameters\n",
    "all_imgs = i_manips.get_images(train_dir)\n",
    "\n",
    "if os.path.isfile(normalize_params_file):\n",
    "    stream = open(normalize_params_file, 'r')\n",
    "    norm_params = yaml.load(stream)\n",
    "else:\n",
    "    norm_params = i_manips.get_normalize_params(all_imgs, num_bands=num_channels)\n",
    "    analysis_utils.write_normalize_values(norm_params, normalize_params_file)\n",
    "\n",
    "means = norm_params[\"means\"]\n",
    "sdevs = norm_params[\"sdevs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    ColorJitter(0.05),\n",
    "    CenterCrop(224),    \n",
    "    ToTensor(),\n",
    "    Normalize([means[0]],\n",
    "              [sdevs[0]])\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize([means[0]],\n",
    "              [sdevs[0]])\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load training data\n",
    "train_data = load_data.CSVDataset(train_dir, train_file, class_file, train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "val_data = load_data.CSVDataset(val_dir, val_file, class_file, val_transforms)\n",
    "\n",
    "val_loader = DataLoader(val_data,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-5.1660, -5.1650, -5.1673,  ..., -5.1668, -5.1679, -5.1695],\n",
      "          [-5.1689, -5.1671, -5.1663,  ..., -5.1668, -5.1684, -5.1700],\n",
      "          [-5.1700, -5.1684, -5.1681,  ..., -5.1689, -5.1684, -5.1665],\n",
      "          ...,\n",
      "          [-5.1729, -5.1740, -5.1700,  ..., -5.1658, -5.1660, -5.1652],\n",
      "          [-5.1713, -5.1747, -5.1729,  ..., -5.1650, -5.1626, -5.1642],\n",
      "          [-5.1718, -5.1692, -5.1700,  ..., -5.1665, -5.1658, -5.1652]],\n",
      "\n",
      "         [[-5.1660, -5.1650, -5.1673,  ..., -5.1668, -5.1679, -5.1695],\n",
      "          [-5.1689, -5.1671, -5.1663,  ..., -5.1668, -5.1684, -5.1700],\n",
      "          [-5.1700, -5.1684, -5.1681,  ..., -5.1689, -5.1684, -5.1665],\n",
      "          ...,\n",
      "          [-5.1729, -5.1740, -5.1700,  ..., -5.1658, -5.1660, -5.1652],\n",
      "          [-5.1713, -5.1747, -5.1729,  ..., -5.1650, -5.1626, -5.1642],\n",
      "          [-5.1718, -5.1692, -5.1700,  ..., -5.1665, -5.1658, -5.1652]],\n",
      "\n",
      "         [[-5.1660, -5.1650, -5.1673,  ..., -5.1668, -5.1679, -5.1695],\n",
      "          [-5.1689, -5.1671, -5.1663,  ..., -5.1668, -5.1684, -5.1700],\n",
      "          [-5.1700, -5.1684, -5.1681,  ..., -5.1689, -5.1684, -5.1665],\n",
      "          ...,\n",
      "          [-5.1729, -5.1740, -5.1700,  ..., -5.1658, -5.1660, -5.1652],\n",
      "          [-5.1713, -5.1747, -5.1729,  ..., -5.1650, -5.1626, -5.1642],\n",
      "          [-5.1718, -5.1692, -5.1700,  ..., -5.1665, -5.1658, -5.1652]]]]), tensor([[[ 91., 166., 112., 194.,   0.],\n",
      "         [181., 138., 196., 162.,   0.]]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "# %pdb\n",
    "for iter_num, data in enumerate(train_loader):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=init_l_rate, weight_decay=w_decay)\n",
    "train_analysis = runtime_logic.ObjectDetection(model,\n",
    "                                                '',\n",
    "                                                means,\n",
    "                                                sdevs,\n",
    "                                                train_loader=train_loader)#,\n",
    "                                                #val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_analysis.instantiate_loss_tracker('outputs')\n",
    "train_analysis.loss_tracker.setup_output_storage(run_name)\n",
    "train_analysis.instantiate_visualiser(tensorboard_outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {# model components\n",
    "             'run_name':run_name,\n",
    "             'optimizer':optimizer,\n",
    "             'criterion':criterion,\n",
    "\n",
    "             # Hyperparameters\n",
    "             'n_epochs':n_epochs,\n",
    "             'batch_size':batch_size,\n",
    "             'lr_decay':lr_decay,\n",
    "             'lr_decay_epoch':lr_decay_epoch,\n",
    "             # 'lr_decay_patience':lr_decay_patience,\n",
    "             # 'class_weights':class_weights,\n",
    "\n",
    "             # Saving & Information retrieval\n",
    "             'report_interval':report_results_per_n_batches,\n",
    "             'save_interval':save_interval,\n",
    "    \n",
    "             'shutdown':shutdown_after,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anteagroup/anaconda3/envs/easy_pytorch/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr decayed by 0.1\n",
      "\n",
      "\n",
      "lr decayed by 0.1\n",
      "\n",
      "\n",
      "lr decayed by 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_analysis.train(arguments)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# train_analysis.loss_tracker.save_model(model, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
