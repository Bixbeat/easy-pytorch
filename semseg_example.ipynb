{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References & related works\n",
    "https://github.com/meetshah1995/pytorch-semseg/blob/master/train.py\n",
    "https://github.com/bfortuner/pytorch_tiramisu/blob/master/camvid_dataset.py\n",
    "https://github.com/bfortuner/pytorch_tiramisu/blob/master/tiramisu-pytorch.ipynb\n",
    "https://github.com/bodokaiser/piwise/blob/master/piwise/transform.py\n",
    "https://github.com/bodokaiser/piwise/blob/master/main.py    \n",
    "\n",
    "Fix conda slow loading https://github.com/pytorch/pytorch/issues/537    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('tensorboard --logdir /tmp/log --host 0.0.0.0 --port 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat url.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.densenet import FCDenseNet103, FCDenseNet67, FCDenseNet57\n",
    "from model.panelnet import PanelNet\n",
    "\n",
    "from processing_utils import image_manipulations as i_manips\n",
    "from processing_utils import runtime_logic\n",
    "from processing_utils import analysis_utils\n",
    "from processing_utils import load_data\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, ColorJitter, FiveCrop, CenterCrop, Lambda, RandomCrop, Resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.cuda.manual_seed(seed)    \n",
    "\n",
    "run_name = \"semseg_test\"\n",
    "data_root = os.path.join(os.getcwd(), \"dummy_data/dummy_tiles\")\n",
    "img_directory = os.path.join(data_root, \"images/train/\")\n",
    "tile_directory = os.path.join(data_root, \"labels/train/\")\n",
    "\n",
    "normalize_params_file = f'outputs/norm_params/{run_name}_norm_params.yaml'\n",
    "previous_model_state = None # Pickled model state dictionary path\n",
    "\n",
    "# Can be set to none if TensorboardX isn't installed\n",
    "tensorboard_outpath = f'outputs/tensorboard/{run_name}_log' # Set to none for temp\n",
    "\n",
    "# Set colour information\n",
    "colours = {'void':[255,255,255],\n",
    "           'building':[255,0,0]}\n",
    "classes = ['void', 'building']\n",
    "\n",
    "n_epochs = 25\n",
    "input_size = 400\n",
    "init_l_rate = 1e-4\n",
    "lr_decay = 0.1\n",
    "# lr_decay_patience = 3\n",
    "lr_decay_epoch = [5, 10, 15]\n",
    "w_decay = 1e-4\n",
    "\n",
    "batch_size = 1\n",
    "num_channels = 3\n",
    "num_classes = 2\n",
    "\n",
    "class_weights = torch.Tensor([1, 1])\n",
    "\n",
    "criterion = nn.NLLLoss(class_weights)\n",
    "if torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "report_results_per_n_batches = {'train':1, 'val':1}\n",
    "save_interval = 9999\n",
    "\n",
    "shutdown_after = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PanelNetTwo(num_classes,\n",
    "#                 num_channels,\n",
    "#                 lyr1_kernels=100,\n",
    "#                 growth_rate=25).apply(analysis_utils.weights_init).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = FCDenseNet57(n_classes=2, in_channels=num_channels)\n",
    "model.apply(analysis_utils.weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(previous_model_state)\n",
    "# model.load_state_dict(state_dict)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get normalize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get normalize parameters\n",
    "all_imgs = i_manips.get_images(img_directory)\n",
    "\n",
    "if os.path.isfile(normalize_params_file):\n",
    "    stream = open(normalize_params_file, 'r')\n",
    "    norm_params = yaml.load(stream)\n",
    "else:\n",
    "    norm_params = i_manips.get_normalize_params(all_imgs, num_bands=num_channels)\n",
    "    analysis_utils.write_normalize_values(norm_params, normalize_params_file)\n",
    "\n",
    "means = norm_params[\"means\"]\n",
    "sdevs = norm_params[\"sdevs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transforms = Compose([\n",
    "    ColorJitter(0.05, 0.05, 0.05),\n",
    "    CenterCrop(input_size),\n",
    "    ToTensor(),\n",
    "    Normalize([means[0],means[1],means[2]],\n",
    "              [sdevs[0],sdevs[1],sdevs[2]])\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    CenterCrop(input_size),\n",
    "    ToTensor(),\n",
    "    Normalize([means[0],means[1],means[2]],\n",
    "              [sdevs[0],sdevs[1],sdevs[2]])\n",
    "])\n",
    "\n",
    "target_transforms = Compose([ \n",
    "    CenterCrop(input_size),    \n",
    "    Lambda(lambda x: torch.LongTensor(np.array(x)))#.squeeze(0))\n",
    "])\n",
    "\n",
    "joint_trans = [\"hflip\"]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Load training data    \n",
    "train_data = load_data.SemSegImageData(split=\"train\",\n",
    "                                       root_path=data_root,\n",
    "                                       input_transform=input_transforms,\n",
    "                                       target_transform=target_transforms,\n",
    "                                       joint_trans=joint_trans)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_data = load_data.SemSegImageData(split = \"val\",\n",
    "                                     root_path=data_root,\n",
    "                                     input_transform=val_transforms,\n",
    "                                     target_transform=target_transforms,\n",
    "                                     joint_trans=joint_trans)\n",
    "\n",
    "val_loader = DataLoader(val_data,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=init_l_rate, weight_decay=w_decay)\n",
    "train_analysis = runtime_logic.SemSegAnalysis(model,\n",
    "                                              classes,\n",
    "                                              means,\n",
    "                                              sdevs,\n",
    "                                              train_loader=train_loader,\n",
    "                                              val_loader=val_loader,\n",
    "                                              label_colors=colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_analysis.instantiate_loss_tracker('outputs')\n",
    "train_analysis.loss_tracker.setup_output_storage(run_name)\n",
    "train_analysis.instantiate_visualiser(tensorboard_outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {# model components\n",
    "             'run_name':run_name,\n",
    "             'optimizer':optimizer,\n",
    "             'criterion':criterion,\n",
    "\n",
    "             # Hyperparameters\n",
    "             'n_epochs':n_epochs,\n",
    "             'batch_size':batch_size,\n",
    "             'lr_decay':lr_decay,\n",
    "             'lr_decay_epoch':lr_decay_epoch,\n",
    "             # 'lr_decay_patience':lr_decay_patience,\n",
    "             # 'class_weights':class_weights,\n",
    "\n",
    "             # Saving & Information retrieval\n",
    "             'report_interval':report_results_per_n_batches,\n",
    "             'save_interval':save_interval,\n",
    "    \n",
    "             'shutdown':shutdown_after,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_analysis.train(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_analysis.loss_tracker.save_model(model, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
